{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ded9841",
   "metadata": {},
   "source": [
    "# EDA Anailisis de Fraude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415235c2",
   "metadata": {},
   "source": [
    "## Caso de Uso:\n",
    "Crear un modelo de aprendizaje supervisado, tipo clasificacion, el cual pueda predecir si una transaccion se trata de un fraude o no en un banco\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed299f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamo las librerías a utilizar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8e717d",
   "metadata": {},
   "source": [
    "### Creacion de las funciones a utilizar en nuestro analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb4abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta funcion ayuda al momento de visualizacion de las diferentes variables dentro del dataset para poder comparar en base \n",
    "#la funcion objetivo como es el comportamiento de la demas variables\n",
    "def dame_variables_categoricas(dataset=None):\n",
    "    if dataset is None:\n",
    "        print(u'\\nFaltan argumentos por pasar a la función')\n",
    "        return 1\n",
    "    lista_variables_categoricas = []\n",
    "    other = []\n",
    "    for i in dataset.columns:\n",
    "        if (dataset[i].dtype!=float) & (dataset[i].dtype!=int):\n",
    "            unicos = int(len(np.unique(dataset[i].dropna(axis=0, how='all'))))\n",
    "            if unicos < 100:\n",
    "                lista_variables_categoricas.append(i)\n",
    "            else:\n",
    "                other.append(i)\n",
    "\n",
    "    return lista_variables_categoricas, other\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_feature(df, col_name, isContinuous, target):\n",
    "    \"\"\"\n",
    "    Visualize a variable with and without faceting on the loan status.\n",
    "    - df dataframe\n",
    "    - col_name is the variable name in the dataframe\n",
    "    - full_name is the full variable name\n",
    "    - continuous is True if the variable is continuous, False otherwise\n",
    "    \"\"\"\n",
    "    f, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12,3), dpi=90)\n",
    "    \n",
    "    count_null = df[col_name].isnull().sum()\n",
    "    if isContinuous:\n",
    "        \n",
    "        sns.histplot(df.loc[df[col_name].notnull(), col_name], kde=False, ax=ax1)\n",
    "    else:\n",
    "        sns.countplot(df[col_name], order=sorted(df[col_name].unique()), color='#5975A4', saturation=1, ax=ax1)\n",
    "    ax1.set_xlabel(col_name)\n",
    "    ax1.set_ylabel('Count')\n",
    "    ax1.set_title(col_name+ ' Numero de nulos: '+str(count_null))\n",
    "    plt.xticks(rotation = 90)\n",
    "\n",
    "\n",
    "    if isContinuous:\n",
    "        sns.boxplot(x=col_name, y=target, data=df, ax=ax2)\n",
    "        ax2.set_ylabel('')\n",
    "        ax2.set_title(col_name + ' by '+target)\n",
    "    else:\n",
    "        data = df.groupby(col_name)[target].value_counts(normalize=True).to_frame('proportion').reset_index() \n",
    "        data.columns = [i, target, 'proportion']\n",
    "        #sns.barplot(x = col_name, y = 'proportion', hue= target, data = data, saturation=1, ax=ax2)\n",
    "        sns.barplot(x = col_name, y = 'proportion', hue= target, data = data, saturation=1, ax=ax2)\n",
    "        ax2.set_ylabel(target+' fraction')\n",
    "        ax2.set_title(target)\n",
    "        plt.xticks(rotation = 90)\n",
    "    ax2.set_xlabel(col_name)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "def get_deviation_of_mean_perc(pd_data, list_variables_numericas, target, multiplier):\n",
    "    \"\"\"\n",
    "    Devuelve el porcentaje de valores que exceden del intervalo de confianza\n",
    "    :type series:\n",
    "    :param multiplier:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    pd_final = pd.DataFrame()\n",
    "    \n",
    "    for i in list_variables_numericas:\n",
    "        \n",
    "        series_mean = pd_data[i].mean()\n",
    "        series_std = pd_data[i].std()\n",
    "        std_amp = multiplier * series_std\n",
    "        left = series_mean - std_amp\n",
    "        right = series_mean + std_amp\n",
    "        size_s = pd_data[i].size\n",
    "        \n",
    "        perc_goods = pd_data[i][(pd_data[i] >= left) & (pd_data[i] <= right)].size/size_s\n",
    "        perc_excess = pd_data[i][(pd_data[i] < left) | (pd_data[i] > right)].size/size_s\n",
    "        \n",
    "        if perc_excess>0:    \n",
    "            pd_concat_percent = pd.DataFrame(pd_data[target][(pd_data[i] < left) | (pd_data[i] > right)]\\\n",
    "                                            .value_counts(normalize=True).reset_index()).T\n",
    "            pd_concat_percent.columns = [pd_concat_percent.iloc[0:], \n",
    "                                          pd_concat_percent.iloc[0:]]\n",
    "            pd_concat_percent = pd_concat_percent.drop('index',axis=0)\n",
    "            pd_concat_percent['variable'] = i\n",
    "            pd_concat_percent['sum_outlier_values'] = pd_data[i][(pd_data[i] < left) | (pd_data[i] > right)].size\n",
    "            pd_concat_percent['porcentaje_sum_null_values'] = perc_excess\n",
    "            pd_final = pd.concat([pd_final, pd_concat_percent], axis=0).reset_index(drop=True)\n",
    "            \n",
    "    if pd_final.empty:\n",
    "        print('No existen variables con valores nulos')\n",
    "        \n",
    "    return pd_final\n",
    "\n",
    "\n",
    "def get_corr_matrix(dataset = None, metodo='pearson', size_figure=[10,8]):\n",
    "    # Para obtener la correlación de Spearman, sólo cambiar el metodo por 'spearman'\n",
    "\n",
    "    if dataset is None:\n",
    "        print(u'\\nHace falta pasar argumentos a la función')\n",
    "        return 1\n",
    "    sns.set(style=\"white\")\n",
    "    # Compute the correlation matrix\n",
    "    corr = dataset.corr(method=metodo) \n",
    "    # Set self-correlation to zero to avoid distraction\n",
    "    for i in range(corr.shape[0]):\n",
    "        corr.iloc[i, i] = 0\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=size_figure)\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(corr, center=0,\n",
    "                square=True, linewidths=.5,  cmap ='viridis' ) #cbar_kws={\"shrink\": .5}\n",
    "    plt.show()\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc12a7e9",
   "metadata": {},
   "source": [
    "## Creacion de dataframes y verificacion de los datos a analizar dentro de los dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f28409",
   "metadata": {},
   "source": [
    "Creamos el dataframe con el que vamos a trabajar y evaluamos las variables y los tipos de variables para identificar si existe la necesidad de hacer cambios en el dataset original para poder seguir con el desarrollo posterior del analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dff405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos el set de datos que vamos a utilizar en el analisis\n",
    "url=\"C:/Users/karla/Documents/CUNEF/5_machine_learning/2_practicas/Fraude/data/Copia de Original_dataset_payments_fraud.csv\"\n",
    "\n",
    "df_fraud=pd.read_csv(url, sep=';')\n",
    "df_fraud.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d1b1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacemos transformacion de variables para las que se encuentran con un formato incorrecto\n",
    "df_fraud=df_fraud.assign(**{'connection_time':lambda df: df['connection_time'].str.replace(',','.').astype(float)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c0cec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos algunas columnas que contienen variables sensibles para el analisis\n",
    "df_fraud=df_fraud.drop([\"race\",\"gender\"],axis=1)\n",
    "df_fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43166d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos que las columnas fueron correctamente eliminadas del dataset y la informacion que se encuentra en el dataset\n",
    "#fue correctamente transformada\n",
    "df_fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6253d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fraud.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cf00da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fraud.dtypes.sort_values().to_frame(\"Type_variable\").groupby(by=\"Type_variable\").size().to_frame('count').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e11980",
   "metadata": {},
   "source": [
    " - Se puede observar que todas las **variables que podrian ser sensibles para el momento del analisis fueron eliminadas,** asi como tambien cada una de las variables se encuentra en su correcta caracteristica luego de las transformaciones realizadas\n",
    " \n",
    " - Del total de las variables obtenidas, se puede resumir que dentro del set de datos que se esta trabajando existen **6 variables enteras, 6 flotantes y 3 variables caracteristicas**. Posteriormente antes del analisis se va a evaluar si estas variables categoricas deben de ser transformada a variable numerica para el correcto analisis con el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bee3a5",
   "metadata": {},
   "source": [
    "## Verificacion de la variable objetivo a trabajar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8527f165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos el comportamiento de la variable objetivo dentro de nuestro dataset para identificar como se procederan a \n",
    "# dividir el set de datos de training y el de test\n",
    "df_fraud_porc=df_fraud.isFraud.value_counts(normalize=True).rename(\"porcentaje\").mul(100).reset_index().round(2)\n",
    "df_fraud_cant=df_fraud.isFraud.value_counts().rename(\"cantidad\").reset_index()\n",
    "\n",
    "df_isFraud=pd.merge(df_fraud_porc, df_fraud_cant, how= \"inner\", on=[\"index\"])\n",
    "df_isFraud=pd.DataFrame(df_isFraud)\n",
    "df_isFraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0138eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=sns.catplot(data=df_isFraud, x=\"index\", y=\"porcentaje\", kind=\"bar\")\n",
    "graph.set(xlabel=\"Existencia de Fraude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c53d04",
   "metadata": {},
   "source": [
    "- En la grafica creada, 0 representan las veces que una transaccion no fue un fraude y 1 aquellas veces que una transaccion si fue un fraude. Podemos ver que los datos de la variable objetivo no estan balanceados, esto quiere decir que existen mas casos en que las transacciones realizadas no fueron fraudes con un 99.89% de los casos, y un restante 0.11% de veces que las transacciones realizadas si fueron fraudes.\n",
    "\n",
    "- Esta gran variacion en relacion a nuestra variable objetivo va a tener un alto impacto al momento de proceder con la division de los datos entre el dataframe de training y el dataframe de test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4267aff3",
   "metadata": {},
   "source": [
    "## Verificacion de datos duplicados y datos faltantes dentro del dataframe creado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef067dcc",
   "metadata": {},
   "source": [
    "### - Verificacion de filas duplicadas dentro del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff41cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificamos si existen duplicados para identificar como proceder csi existe gran cantidad\n",
    "print(df_fraud.shape, df_fraud.drop_duplicates().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6e550c",
   "metadata": {},
   "source": [
    "- En el dataset con el cual estamos trabajando **no existen valores duplicados** por tanto nuestro dataset no sufre ninguna modificacion en esta etapa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f704452",
   "metadata": {},
   "source": [
    "### - Verificar de valores faltantes o nulos dentro del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e497fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_columns=df_fraud.isnull().sum().sort_values(ascending=False).rename(\"null_values\").reset_index()\n",
    "total_rows=df_fraud.count().rename(\"total_rows\").astype(int).reset_index()\n",
    "\n",
    "\n",
    "null_columns=pd.merge(null_columns,total_rows, how=\"inner\", on=[\"index\"])\n",
    "null_columns[\"miss_percentage\"]=(null_columns['null_values']/len(df_fraud)).mul(100)\n",
    "null_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d9c6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fraud.device.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e037aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificacion de filas con valores faltantes\n",
    "null_rows=df_fraud.isnull().sum(axis = 1).sort_values(ascending=False)#.rename(\"null_values\").reset_index()\n",
    "null_rows.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b778e3",
   "metadata": {},
   "source": [
    "- El analisis muestra que para las columnas de \"device\", asi como \"zone\", el aproximadamente 9% de los datos se encuentran como nulos, como la cantidad de nulos es muy reducida entonces **se sigue trabajando con estas columnas.**\n",
    "- En relacion a las filas, no existe ninguna fila con valores nulos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8f2264",
   "metadata": {},
   "source": [
    "## Comportamiento de cada una de las variables a analizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4fb984",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for i in list(df_fraud.columns):\n",
    "    if (df_fraud[i].dtype==float) & (i!='isFraud'):\n",
    "         plot_feature(df_fraud, col_name=i, isContinuous=True, target='isFraud')\n",
    "    elif  i!='isFraud':\n",
    "        plot_feature(df_fraud, col_name=i, isContinuous=False, target='isFraud')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practica_0",
   "language": "python",
   "name": "practica_0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
